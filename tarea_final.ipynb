{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEMA 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Random, Distributions\n",
    "\n",
    "# Parámetros\n",
    "μ = 2.0\n",
    "σ2 = 1.5\n",
    "n = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Simulación de observaciones\n",
    "\n",
    "Dada una variable aleatoria $ Y_i \\sim \\text{Normal}(\\mu, \\sigma^2) $, generamos una muestra de tamaño $ n = 10 $. Cada observación se obtiene de la siguiente manera:\n",
    "\n",
    "$$\n",
    "y_i \\sim \\text{Normal}(\\mu, \\sigma^2), \\quad i = 1, 2, \\dots, 10\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observaciones simuladas: [1.098645090828223, -0.1472945661191872, 2.2068525185559404, 2.7879610634525993, 3.926574233118528, 3.807456216781026, 1.9699011016821755, 1.8887591696650845, 0.9172911046082523, 2.0136345733098664]\n"
     ]
    }
   ],
   "source": [
    "# a) Generar observaciones\n",
    "y = rand(Normal(μ, sqrt(σ2)), n)\n",
    "println(\"Observaciones simuladas: \", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Función de verosimilitud y log-verosimilitud\n",
    "\n",
    "La **función de verosimilitud** para un conjunto de observaciones $ y = (y_1, y_2, \\dots, y_n) $ bajo la suposición de que los $ Y_i $ son independientes y distribuidos como $ \\text{Normal}(\\mu, \\sigma^2) $ está dada por:\n",
    "\n",
    "$$\n",
    "L(\\mu, \\sigma^2 \\mid y) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\mu)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "La **log-verosimilitud** es la siguiente:\n",
    "\n",
    "$$\n",
    "\\ell(\\mu, \\sigma^2 \\mid y) = -\\frac{n}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verosimilitud: 1.1629415861167337e-7\n",
      "Log-verosimilitud: -15.967143005581974\n"
     ]
    }
   ],
   "source": [
    "# b) Función de verosimilitud\n",
    "function verosimilitud(y, μ, σ2)\n",
    "    n = length(y)\n",
    "    (1 / ((2 * π * σ2)^(n/2))) * exp(-sum((y .- μ).^2) / (2 * σ2))\n",
    "end\n",
    "\n",
    "# Log-verosimilitud\n",
    "function log_verosimilitud(y, μ, σ2)\n",
    "    n = length(y)\n",
    "    -(n/2) * log(2 * π * σ2) - sum((y .- μ).^2) / (2 * σ2)\n",
    "end\n",
    "\n",
    "println(\"Verosimilitud: \", verosimilitud(y, μ, σ2))\n",
    "println(\"Log-verosimilitud: \", log_verosimilitud(y, μ, σ2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Función score y la información de Fisher\n",
    "\n",
    "La **función score** es la derivada de la log-verosimilitud con respecto a los parámetros $ \\mu $ y $ \\sigma^2 $:\n",
    "\n",
    "Para $ \\mu $:\n",
    "\n",
    "$$\n",
    "S_{\\mu}(\\mu, \\sigma^2) = \\frac{\\partial \\ell(\\mu, \\sigma^2 \\mid y)}{\\partial \\mu} = \\frac{1}{\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)\n",
    "$$\n",
    "\n",
    "Para $ \\sigma^2 $:\n",
    "\n",
    "$$\n",
    "S_{\\sigma^2}(\\mu, \\sigma^2) = \\frac{\\partial \\ell(\\mu, \\sigma^2 \\mid y)}{\\partial \\sigma^2} = -\\frac{n}{2\\sigma^2} + \\frac{1}{2\\sigma^4} \\sum_{i=1}^{n} (y_i - \\mu)^2\n",
    "$$\n",
    "\n",
    "La **información de Fisher** es la matriz de varianza-covarianza inversa de los estimadores de máxima verosimilitud, cuyas entradas son los valores \n",
    "esperados de los productos de las derivadas de la log-verosimilitud:\n",
    "\n",
    "Para $ \\mu $ y $ \\sigma^2 $:\n",
    "\n",
    "$$\n",
    "\\mathcal{I}(\\mu, \\sigma^2) = \n",
    "\\begin{pmatrix}\n",
    "\\frac{n}{\\sigma^2} & 0 \\\\\n",
    "0 & \\frac{n}{2\\sigma^4}\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: (0.3131870039216724, -0.16637857800371814)\n",
      "Información de Fisher: (6.666666666666667, 0, 2.2222222222222223)\n"
     ]
    }
   ],
   "source": [
    "# c) Función score para μ y σ2\n",
    "function score(y, μ, σ2)\n",
    "    n = length(y)\n",
    "    dL_dμ = sum(y .- μ) / σ2\n",
    "    dL_dσ2 = -(n / (2 * σ2)) + sum((y .- μ).^2) / (2 * σ2^2)\n",
    "    return dL_dμ, dL_dσ2\n",
    "end\n",
    "\n",
    "# Información de Fisher\n",
    "function fisher_information(y, μ, σ2)\n",
    "    n = length(y)\n",
    "    I_μμ = n / σ2\n",
    "    I_μσ2 = 0\n",
    "    I_σ2σ2 = n / (2 * σ2^2)\n",
    "    return I_μμ, I_μσ2, I_σ2σ2\n",
    "end\n",
    "\n",
    "println(\"Score: \", score(y, μ, σ2))\n",
    "println(\"Información de Fisher: \", fisher_information(y, μ, σ2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Intervalos de confianza usando el estimador de máxima verosimilitud\n",
    "\n",
    "Los **estimadores de máxima verosimilitud** para $ \\mu $ y $ \\sigma^2 $ son:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^{n} y_i, \\quad \\hat{\\sigma}^2 = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{\\mu})^2\n",
    "$$\n",
    "\n",
    "Para el intervalo de confianza de $ \\mu $:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} \\pm z_{\\alpha/2} \\cdot \\sqrt{\\frac{\\hat{\\sigma}^2}{n}}\n",
    "$$\n",
    "\n",
    "donde $ z_{\\alpha/2} $ es el valor crítico de la distribución normal estándar.\n",
    "\n",
    "Para $ \\sigma^2 $, el intervalo de confianza es:\n",
    "\n",
    "$$\n",
    "\\left( \\frac{(n-1)\\hat{\\sigma}^2}{\\chi^2_{\\alpha/2, n-1}}, \\frac{(n-1)\\hat{\\sigma}^2}{\\chi^2_{1-\\alpha/2, n-1}} \\right)\n",
    "$$\n",
    "\n",
    "donde $ \\chi^2_{\\alpha, k} $ es el valor crítico de la distribución chi-cuadrado con $ k $ grados de libertad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervalo de confianza para μ: (1.26765505612418, 2.8263010450523223)\n",
      "Intervalo de confianza para σ2: (0.748010340936224, 5.269323935201218)\n"
     ]
    }
   ],
   "source": [
    "# d) Estimador de máxima verosimilitud para μ y σ2\n",
    "μ_hat = mean(y)\n",
    "σ2_hat = var(y)\n",
    "\n",
    "# Intervalos de confianza\n",
    "α = 0.05  # Nivel de significancia\n",
    "z = quantile(Normal(0, 1), 1 - α/2)\n",
    "\n",
    "conf_μ = (μ_hat - z * sqrt(σ2_hat / n), μ_hat + z * sqrt(σ2_hat / n))\n",
    "conf_σ2 = (σ2_hat * (n - 1) / quantile(Chisq(n - 1), 1 - α/2), σ2_hat * (n - 1) / quantile(Chisq(n - 1), α/2))\n",
    "\n",
    "println(\"Intervalo de confianza para μ: \", conf_μ)\n",
    "println(\"Intervalo de confianza para σ2: \", conf_σ2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Intervalos de confianza usando la devianza\n",
    "\n",
    "La **devianza** es una medida de la calidad del ajuste del modelo. Se define como:\n",
    "\n",
    "$$\n",
    "D = -2 \\cdot \\ell(\\hat{\\mu}, \\hat{\\sigma}^2 \\mid y)\n",
    "$$\n",
    "\n",
    "Para construir intervalos de confianza usando la devianza, se compara con la distribución $ \\chi^2 $ asintótica bajo ciertas condiciones del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervalo de confianza usando la devianza: [31.960487866261573, 36.98339198445929]\n"
     ]
    }
   ],
   "source": [
    "# e) Función de devianza\n",
    "function devianza(y, μ_hat, σ2_hat)\n",
    "    -2 * log_verosimilitud(y, μ_hat, σ2_hat)\n",
    "end\n",
    "\n",
    "# Intervalos de confianza con la devianza (asume chi-cuadrado)\n",
    "conf_devianza = [devianza(y, μ_hat, σ2_hat) + quantile(Chisq(1), α/2), devianza(y, μ_hat, σ2_hat) + quantile(Chisq(1), 1 - α/2)]\n",
    "println(\"Intervalo de confianza usando la devianza: \", conf_devianza)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Prueba de hipótesis usando la razón de verosimilitudes\n",
    "\n",
    "Para probar la hipótesis $ H_0: \\mu_1 = \\mu_2 $ contra $ H_1: \\mu_1 \\neq \\mu_2 $, usamos la **razón de verosimilitudes**:\n",
    "\n",
    "$$\n",
    "\\Lambda = -2\\left[ \\ell(\\hat{\\mu}, \\hat{\\sigma}^2 \\mid y) - (\\ell(\\hat{\\mu}_1, \\hat{\\sigma}^2_1 \\mid y_1) + \\ell(\\hat{\\mu}_2, \\hat{\\sigma}^2_2 \\mid y_2))\\right]\n",
    "$$\n",
    "\n",
    "Este estadístico bajo $ H_0 $ se distribuye asintóticamente como una $ \\chi^2 $ con un grado de libertad, y el p-valor asociado nos permite tomar una decisión sobre $ H_0 $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Razón de verosimilitudes: 0.8249739496052939\n",
      "P-valor: 0.36372990193674193\n"
     ]
    }
   ],
   "source": [
    "# f) Simular segunda muestra\n",
    "x = rand(Normal(3.0, sqrt(σ2)), n)\n",
    "\n",
    "# Hipótesis nula: μ1 = μ2\n",
    "# Hipótesis alternativa: μ1 ≠ μ2\n",
    "logL0 = log_verosimilitud([y; x], mean([y; x]), σ2_hat)  # Bajo H0\n",
    "logL1 = log_verosimilitud(y, mean(y), σ2_hat) + log_verosimilitud(x, mean(x), σ2_hat)  # Bajo H1\n",
    "\n",
    "# Estadístico de prueba\n",
    "LR = -2 * (logL0 - logL1)\n",
    "\n",
    "# P-valor\n",
    "p_value = 1 - cdf(Chisq(1), LR)\n",
    "println(\"Razón de verosimilitudes: \", LR)\n",
    "println(\"P-valor: \", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEMA 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Derivación de la distribución posterior condicional $\\pi(\\mu \\mid \\sigma^2, \\mathbf{y})$\n",
    "\n",
    "Dada la muestra $\\mathbf{y} = (y_1, y_2, \\dots, y_n)$, y suponiendo que $\\sigma^2$ es conocida:\n",
    "\n",
    "1. **Modelo**: Supongamos que los datos son independientes y normalmente distribuidos:\n",
    "   $$\n",
    "   y_i \\mid \\mu, \\sigma^2 \\sim \\text{Normal}(\\mu, \\sigma^2), \\quad i = 1, 2, \\dots, n\n",
    "   $$\n",
    "   Es decir, la función de verosimilitud es:\n",
    "   $$\n",
    "   p(\\mathbf{y} \\mid \\mu, \\sigma^2) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\mu)^2}{2\\sigma^2}\\right)\n",
    "   $$\n",
    "   Esto se puede escribir como:\n",
    "   $$\n",
    "   p(\\mathbf{y} \\mid \\mu, \\sigma^2) = \\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\right)^n \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)^2\\right)\n",
    "   $$\n",
    "\n",
    "2. **Prior de $\\mu$**: El prior de $\\mu$ es una distribución normal:\n",
    "   $$\n",
    "   \\mu \\sim \\text{Normal}(\\mu_0, \\sigma_0^2)\n",
    "   $$\n",
    "   Entonces, la función de densidad del prior es:\n",
    "   $$\n",
    "   p(\\mu) = \\frac{1}{\\sqrt{2\\pi\\sigma_0^2}} \\exp\\left(-\\frac{(\\mu - \\mu_0)^2}{2\\sigma_0^2}\\right)\n",
    "   $$\n",
    "\n",
    "3. **Posterior de $\\mu$**: La posterior de $\\mu$ dado $\\sigma^2$ y los datos es proporcional al producto de la verosimilitud y el prior:\n",
    "   $$\n",
    "   p(\\mu \\mid \\sigma^2, \\mathbf{y}) \\propto p(\\mathbf{y} \\mid \\mu, \\sigma^2) p(\\mu)\n",
    "   $$\n",
    "   Sustituyendo las expresiones de la verosimilitud y el prior:\n",
    "   $$\n",
    "   p(\\mu \\mid \\sigma^2, \\mathbf{y}) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)^2 - \\frac{1}{2\\sigma_0^2} (\\mu - \\mu_0)^2\\right)\n",
    "   $$\n",
    "\n",
    "4. **Completando el cuadrado**: Simplificamos la expresión completando el cuadrado en $\\mu$:\n",
    "   $$\n",
    "   p(\\mu \\mid \\sigma^2, \\mathbf{y}) \\propto \\exp\\left(-\\frac{1}{2}\\left(\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}\\right) \\left(\\mu - \\mu_n\\right)^2\\right)\n",
    "   $$\n",
    "   donde:\n",
    "   $$\n",
    "   \\mu_n = \\frac{\\frac{\\mu_0}{\\sigma_0^2} + \\frac{n\\bar{y}}{\\sigma^2}}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}, \\quad \\sigma_n^2 = \\left(\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}\\right)^{-1}\n",
    "   $$\n",
    "   Así, se obtiene que:\n",
    "   $$\n",
    "   \\mu \\mid \\sigma^2, \\mathbf{y} \\sim \\text{Normal}(\\mu_n, \\sigma_n^2)\n",
    "   $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución a posteriori condicional de μ | σ², y:\n",
      "μ ~ Normal(0.5066666666666667, 0.408248290463863)\n"
     ]
    }
   ],
   "source": [
    "using Distributions\n",
    "\n",
    "# Parámetros a priori\n",
    "μ0 = 0.0\n",
    "σ0² = 1.0\n",
    "\n",
    "# Datos simulados\n",
    "y = [2.5, 3.1, 2.8, 3.6, 3.2]\n",
    "n = length(y)\n",
    "ȳ = mean(y)\n",
    "\n",
    "# Dado un valor de σ²\n",
    "σ² = 1.0  # Supón que es un valor conocido o inicial\n",
    "\n",
    "# Parámetros de la distribución a posteriori de μ\n",
    "μ_n = (σ0² * ȳ + σ² * μ0) / (n * σ0² + σ²)\n",
    "σ_n² = (σ0² * σ²) / (n * σ0² + σ²)\n",
    "\n",
    "# Distribución a posteriori condicional de μ dado σ² y y\n",
    "posterior_μ = Normal(μ_n, sqrt(σ_n²))\n",
    "\n",
    "# Print para la sección (a)\n",
    "println(\"Distribución a posteriori condicional de μ | σ², y:\")\n",
    "println(\"μ ~ Normal($μ_n, $(sqrt(σ_n²)))\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Derivación de la distribución posterior condicional $\\pi(\\sigma^2 \\mid \\mu, \\mathbf{y})$\n",
    "\n",
    "Dada la muestra $\\mathbf{y} = (y_1, y_2, \\dots, y_n)$, y suponiendo que $\\mu$ es conocida:\n",
    "\n",
    "1. **Modelo**: Como antes, los datos siguen una distribución normal:\n",
    "   $$\n",
    "   y_i \\mid \\mu, \\sigma^2 \\sim \\text{Normal}(\\mu, \\sigma^2)\n",
    "   $$\n",
    "   Entonces, la función de verosimilitud es:\n",
    "   $$\n",
    "   p(\\mathbf{y} \\mid \\mu, \\sigma^2) = \\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\right)^n \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)^2\\right)\n",
    "   $$\n",
    "\n",
    "2. **Prior de $\\sigma^2$**: El prior de $\\sigma^2$ es una distribución Inversa Gamma:\n",
    "   $$\n",
    "   \\sigma^2 \\sim \\text{InverseGamma}(a, b)\n",
    "   $$\n",
    "   Entonces, la función de densidad del prior es:\n",
    "   $$\n",
    "   p(\\sigma^2) \\propto (\\sigma^2)^{-(a+1)} \\exp\\left(-\\frac{b}{\\sigma^2}\\right)\n",
    "   $$\n",
    "\n",
    "3. **Posterior de $\\sigma^2$**: La posterior de $\\sigma^2$ dado $\\mu$ y los datos es proporcional al producto de la verosimilitud y el prior:\n",
    "   $$\n",
    "   p(\\sigma^2 \\mid \\mu, \\mathbf{y}) \\propto p(\\mathbf{y} \\mid \\mu, \\sigma^2) p(\\sigma^2)\n",
    "   $$\n",
    "   Sustituyendo las expresiones de la verosimilitud y el prior:\n",
    "   $$\n",
    "   p(\\sigma^2 \\mid \\mu, \\mathbf{y}) \\propto (\\sigma^2)^{-\\frac{n}{2} - (a + 1)} \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)^2 - \\frac{b}{\\sigma^2}\\right)\n",
    "   $$\n",
    "\n",
    "4. **Reconociendo la forma**: Esta expresión es de la forma de una distribución Inversa Gamma:\n",
    "   $$\n",
    "   p(\\sigma^2 \\mid \\mu, \\mathbf{y}) \\sim \\text{InverseGamma}\\left(a_n, b_n\\right)\n",
    "   $$\n",
    "   donde:\n",
    "   $$\n",
    "   a_n = a + \\frac{n}{2}, \\quad b_n = b + \\frac{1}{2} \\sum_{i=1}^{n} (y_i - \\mu)^2\n",
    "   $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución a posteriori condicional de σ² | μ, y:\n",
      "σ² ~ InverseGamma(4.5, 2.35)\n"
     ]
    }
   ],
   "source": [
    "# Parámetros a priori\n",
    "a = 2.0\n",
    "b = 2.0\n",
    "\n",
    "# Supón un valor conocido o inicial de μ\n",
    "μ = 3.0  # Puedes usar el valor que sea relevante\n",
    "\n",
    "# Parámetros de la distribución a posteriori de σ²\n",
    "α_n = a + n/2\n",
    "β_n = b + 0.5 * sum((y .- μ).^2)\n",
    "\n",
    "# Distribución a posteriori condicional de σ² dado μ y y\n",
    "posterior_σ² = InverseGamma(α_n, β_n)\n",
    "\n",
    "# Print para la sección (b)\n",
    "println(\"Distribución a posteriori condicional de σ² | μ, y:\")\n",
    "println(\"σ² ~ InverseGamma($α_n, $β_n)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Implementación del Muestreo de Gibbs\n",
    "\n",
    "El muestreo de Gibbs es una técnica de muestreo secuencial que se basa en muestrear de las distribuciones condicionales completas:\n",
    "\n",
    "1. **Inicialización**: Asigne valores iniciales $\\mu^{(0)}$ y $\\sigma^{2(0)}$.\n",
    "2. **Iteración**:\n",
    "   - Muestree $\\mu^{(t)} \\sim \\text{Normal}(\\mu_n, \\sigma_n^2)$ dado $\\sigma^{2(t-1)}$.\n",
    "   - Muestree $\\sigma^{2(t)} \\sim \\text{InverseGamma}(a_n, b_n)$ dado $\\mu^{(t)}$.\n",
    "\n",
    "Se repite estos pasos para obtener una cadena de muestras $\\{(\\mu^{(t)}, \\sigma^{2(t)})\\}_{t=1}^{T}$ que convergerá a la distribución conjunta posterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestreo de Gibbs completado con 10000 iteraciones.\n",
      "\n",
      "Algunas realizaciones de las muestras de μ y σ²:\n",
      "Iteración 1: μ = 0.2512077461027267, σ² = 6.833180432768631\n",
      "Iteración 2: μ = 0.17070272925518157, σ² = 19.502577936737215\n",
      "Iteración 3: μ = 0.07177442053814564, σ² = 5.6618119008242545\n",
      "Iteración 4: μ = -0.11176731920741267, σ² = 7.9465581503106275\n",
      "Iteración 5: μ = 1.0004785080504304, σ² = 3.86140944668989\n"
     ]
    }
   ],
   "source": [
    "iterations = 10000\n",
    "burn_in = 2000\n",
    "μ_samples = zeros(iterations)\n",
    "σ²_samples = zeros(iterations)\n",
    "\n",
    "# Valores iniciales\n",
    "μ_samples[1] = mean(y)\n",
    "σ²_samples[1] = var(y)\n",
    "\n",
    "# Iteraciones del muestreo de Gibbs\n",
    "for i in 2:iterations\n",
    "    # Muestreo de μ dado σ², y\n",
    "    σ² = σ²_samples[i-1]\n",
    "    μ_n = (σ0² * ȳ + σ² * μ0) / (n * σ0² + σ²)\n",
    "    σ_n² = (σ0² * σ²) / (n * σ0² + σ²)\n",
    "    μ_samples[i] = rand(Normal(μ_n, sqrt(σ_n²)))\n",
    "    \n",
    "    # Muestreo de σ² dado μ, y\n",
    "    α_n = a + n/2\n",
    "    β_n = b + 0.5 * sum((y .- μ_samples[i]).^2)\n",
    "    σ²_samples[i] = 1 / rand(Gamma(α_n, 1/β_n))\n",
    "end\n",
    "\n",
    "# Print para la sección (c)\n",
    "println(\"Muestreo de Gibbs completado con $iterations iteraciones.\")\n",
    "\n",
    "# Mostrar algunas realizaciones de las muestras\n",
    "println(\"\\nAlgunas realizaciones de las muestras de μ y σ²:\")\n",
    "for i in 1:5  # Imprime las primeras 5 realizaciones como ejemplo\n",
    "    println(\"Iteración $i: μ = $(μ_samples[i + burn_in]), σ² = $(σ²_samples[i + burn_in])\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### (d) Inferencia a partir de la distribución posterior\n",
    "\n",
    "Usando las muestras obtenidas del muestreo de Gibbs, se pueden calcular las inferencias puntuales (como la media posterior de $\\mu$ y $\\sigma^2$) y los intervalos de credibilidad (por ejemplo, los percentiles 2.5% y 97.5% para construir intervalos de credibilidad del 95%).\n",
    "\n",
    "Cada uno de estos pasos se basa en derivaciones matemáticas de las propiedades de las distribuciones normales y de la distribución Inversa Gamma, junto con el uso de propiedades de completado del cuadrado y de muestreo secuencial en cadenas de Markov.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la inferencia:\n",
      "Media posterior de μ: 0.2933747548496111\n",
      "Intervalo creíble del 95% para μ: [-1.2035338934446984, 1.6887523783577925]\n",
      "Media posterior de σ²: 6.517111404570587\n",
      "Intervalo creíble del 95% para σ²: [1.2532430193759119, 20.310649598027446]\n"
     ]
    }
   ],
   "source": [
    "# Descartar el burn-in\n",
    "μ_samples = μ_samples[burn_in+1:end]\n",
    "σ²_samples = σ²_samples[burn_in+1:end]\n",
    "\n",
    "# Calcular la media posterior y los intervalos creíbles\n",
    "μ_mean = mean(μ_samples)\n",
    "σ²_mean = mean(σ²_samples)\n",
    "μ_cred_int = quantile(μ_samples, [0.025, 0.975])\n",
    "σ²_cred_int = quantile(σ²_samples, [0.025, 0.975])\n",
    "\n",
    "# Print para la sección (d)\n",
    "println(\"Resultados de la inferencia:\")\n",
    "println(\"Media posterior de μ: $μ_mean\")\n",
    "println(\"Intervalo creíble del 95% para μ: $μ_cred_int\")\n",
    "println(\"Media posterior de σ²: $σ²_mean\")\n",
    "println(\"Intervalo creíble del 95% para σ²: $σ²_cred_int\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
